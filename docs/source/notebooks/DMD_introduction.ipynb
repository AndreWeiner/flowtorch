{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Dynamic Mode Decomposition (DMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "\n",
    "Approximate the leading eigencomposition of (high dimensional) linear operator $A \\in \\mathbb{C}^{n \\times n}$ where $X'=AX$ to find spacial temporal coherant modes of the (possibly non-linear) system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math #since torch doesn't have a built in pi function\n",
    "import torch as pt\n",
    "import numpy as np\n",
    "\n",
    "pt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs to DMD\n",
    "\n",
    "$n$ is the number of spatial points saved per shot and $m$ is the number of snapshots taken.\n",
    "\n",
    "- Snapshot of fluid flow (long and skinny) $X = \n",
    " \\begin{bmatrix}\n",
    "  \\vert & \\vert &     & \\vert \\\\\n",
    "  x_1   & x_2   & ... & x_{m-1} \\\\\n",
    "  \\vert & \\vert &     & \\vert\n",
    " \\end{bmatrix} \\in \\mathbb{C}^{n \\times (m-1)}$\n",
    "\n",
    "- Snapshot of fluid flow evolved by one unit in time $X' = \n",
    " \\begin{bmatrix}\n",
    "  \\vert & \\vert &     & \\vert \\\\\n",
    "  x_2   & x_3   & ... & x_{m} \\\\\n",
    "  \\vert & \\vert &     & \\vert\n",
    " \\end{bmatrix} \\in \\mathbb{C}^{n \\times (m-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Inputs\n",
    " In this introduction, we will add together the following functions f1, f2, and f3 to create artificial test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmd wird kein img Anteil haben\n",
    "\n",
    "#maybe do dmd in im and re, or change functions to re only\n",
    "\n",
    "#img Funktionen austauschen mit reel (plot ~ gleich)\n",
    "\n",
    "def f1(Xm, Tm, z):\n",
    "    return pt.multiply(20-0.2*pt.pow(Xm, 2), pt.exp(z*Tm)).T\n",
    "\n",
    "def f2(Xm, Tm, z):\n",
    "    return pt.multiply(Xm, pt.exp(z*Tm)).T\n",
    "\n",
    "def f3(Xm, Tm, z):\n",
    "    return pt.multiply(10*pt.tanh(Xm/2)/pt.cosh(Xm/2), pt.exp(z*Tm)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meshgrid\n",
    "A small meshgrid is created for calculating points of the functions. \n",
    "\n",
    "*Note: The inputs of Pytorch.meshgrid(t,x) are flipped compared to numpy.meshgrid(x,t). See [documentation](https://pytorch.org/docs/master/generated/torch.meshgrid.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesh(x_start, x_end, n_x, t_start, t_end, n_t):\n",
    "    x = pt.linspace(x_start, x_end, n_x)\n",
    "    t = pt.linspace(t_start, t_end, n_t)\n",
    "    return pt.meshgrid(t, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data and calling DMD function\n",
    "\n",
    "The mesh is created, the functions are combined, and the DMD function is called with a rank of 3.\n",
    "\n",
    "Note: PyTorch has no built in Pi-Function, so we \"create\" our own. See [forum post](https://discuss.pytorch.org/t/np-pi-equivalent-in-pytorch/67157)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.complex64\n",
      "torch.float32\n",
      "torch.complex64\n"
     ]
    }
   ],
   "source": [
    "pt.pi = pt.acos(pt.zeros(1)).item()*2 # PyTorch has no built in Pi function\n",
    "\n",
    "def main():\n",
    "    Tm, Xm = create_mesh(-10, 10, 100, 0, 6*pt.pi, 80)\n",
    "    X_1r = f1(Xm, Tm, -0.05+2.3j)\n",
    "    X_2 = f2(Xm, Tm, 0.6j)\n",
    "    X_3r = f3(Xm, Tm, 0.1+2.8j)\n",
    "    data = X_1r + X_2 + X_3r\n",
    "\n",
    "    rank=3\n",
    "    dmd(data, rank=rank)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMD at a Glance:\n",
    "\n",
    "**1. Compute Singular Value Decomposition (SVD) of big data matrix $X$ to find the dominant coherent structures (Columns of $U$).**\n",
    "\n",
    "The exact SVD is reduced when, for example, 99% of the system energy is captured by the first $r$ comumns of $U$. The * denotes the conjugate transpose.\n",
    "\n",
    "$$ X = U\\Sigma V^* $$\n",
    "\n",
    "**2. Project $A$ on the dominant singular vectors $U^*$ and $U$ to get the reduced dynamic operator $\\tilde{A}$**\n",
    "\n",
    "$X$ is replaced in $X' = AX$ with matrices from the SVD, which results in $ X' = AU\\Sigma V^* $. Instead of doing a (very demanding) pseudo-inverse to find $A$, we project $\\tilde{A}$ onto our dominant singluar vectors $U^*$ and $U$. $\\tilde{A}$, which is only of the magnitude of time (much smaller than $A$), is a linear best fit dynamical system, that tell you how your POD modes evolve over time.\n",
    "\n",
    "$$U^*X'V\\Sigma^{-1} = U^*AU = \\tilde{A}$$\n",
    "\n",
    "**3. Compute the eigenvalues $\\Lambda$ and eigenvectors $W$ of $\\tilde{A}$**\n",
    "\n",
    "$\\tilde{A}$ has the same non-zero *eigenvalues* as $A$.\n",
    "\n",
    "$$\\tilde{A}W = W\\Lambda$$\n",
    "\n",
    "**4. Compute the eigenvectors $\\Phi$ of $A$**\n",
    "\n",
    "The eigenvectors $\\Phi$ are also called modes.\n",
    "\n",
    "$$\\Phi = X'V\\Sigma^{-1}W$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)\n",
    "\n",
    "A function is defined to compute the SVD, which will be used for the DMD later. pt.svd() returns the reduced SVD by default.\n",
    "\n",
    "pt.svd returns $V$, not $V*$ (conj. transposed), which is useful, since we need $V$ for step 4. $\\Sigma$ will always be a real-valued, which is important for this example.\n",
    "\n",
    "We truncate at 3 modes (Why?)\n",
    "\n",
    "Columns of U are our POD modes. For more on POD, check out the [notebook](POD_introduction.ipynb).\n",
    "\n",
    "*Note: torch.svd() is depricated. In torch 1.8, [torch.linalg.svd](https://pytorch.org/docs/1.8.0/linalg.html#torch.linalg.svd) will function like numpy.linalg.svd(), but this is not available in Version 1.7.1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(matrix, rank=None):\n",
    "    U, s, V = pt.svd(matrix, some=False)  #returns V, not V*\n",
    "    print(U.dtype)\n",
    "    print(s.dtype)\n",
    "    print(V.dtype)\n",
    "    if rank is None:\n",
    "        rank = s.shape[0]\n",
    "    return U[:, :rank], s[:rank], V[:, :rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Mode Decomposition (DMD)\n",
    "\n",
    "After finding the SVD of our matrix, we can find $\\tilde{A} = U^*X'V\\Sigma^{-1}$.\n",
    "\n",
    "$\\Sigma$ is a diagonal matrix and can therefore be inversed using 1/diag_elements.\n",
    "\n",
    "After finding $\\tilde{A}$, the eigenvalues and eigenvectors can be computed using pt.eig(). Since Pytorch does not currently support complex tensor operations (see [forum](https://discuss.pytorch.org/t/how-to-use-complex-eigenvalues/71983)), we will use np.linalg.eig() for this example.\n",
    "\n",
    "Finally, the eigenvectors of A $\\Phi$ are computed and returned together with the eigenvalues (same for A and At). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmd(matrix, rank=None):\n",
    "    U, s, V = svd(matrix[:,:-1], rank)\n",
    "    s_inv = pt.diag(1.0/s).type(pt.complex64) #type cast since Sigma is real (not necessary when using only real data)\n",
    "    \n",
    "    At = U.conj().T @ matrix[:, 1:] @ V @ s_inv #At = torch.mm(torch.mm(torch.mm(U.conj().T, matrix[:, 1:]), V), s_inv) not necessary because @ works too\n",
    "    \n",
    "    val, vec = np.linalg.eig(At)\n",
    "    #val, vec = torch.eig(At, eigenvectors=True)\n",
    "    \n",
    "    phi = matrix[:, 1:] @ V @ s_inv @ vec\n",
    "    return (val, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now what?\n",
    "\n",
    "\n",
    "With our (spacial) modes $\\Phi$ and (temporal) eigenvalues $\\Lambda$, we can predict what the system will do in the future.\n",
    "\n",
    "$$\\hat{X}(k\\Delta t) = \\Phi\\Lambda^kb_0$$\n",
    "\n",
    "$\\hat{X}$ is a future state prediction of $X$.\n",
    "\n",
    "$\\Lambda^k$ advances one time increment $\\Delta t$ with each $k$.\n",
    "\n",
    "$b_0$ is amplitude of modes. Condition for how much each mode is expressed in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "- use docstring with ''' notation, look at flowtorch/data/foamdataloader source code\n",
    "\n",
    "- is rank of DMD always known? why do we truncate if we can do econ SVD? Can we find rank using dominant coherant structures of U? Is that what s.shape[0] does?\n",
    "\n",
    "- is the \"now what\" correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Kutz, J. N., Brunton, S. L. 1., Brunton, B. W., & Proctor, J. L. (2016). *Dynamic Mode Decomposition.* Philadelphia, PA, USA: Society for Industrial and Applied Mathematics.\n",
    "2. Taylor, R. (2016) Dynamic Mode Decomposition in Python. *Pyrunner.* Accessed: 25 January 2021. http://www.pyrunner.com/weblog/2016/07/25/dmd-python/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
